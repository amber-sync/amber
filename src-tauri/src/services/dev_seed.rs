//! Development data seeding for testing Timeline and FTS5 performance
//!
//! This module imports pre-generated mock data from the `mock-data/` folder.
//! The data is generated by `scripts/dev/generate-mock-data.py` which creates:
//! - Three jobs: "Documents Backup", "Media Archive", and "Stress Test"
//! - Multiple snapshots with realistic file structures
//! - Per-destination SQLite indexes at `.amber-meta/index.db`
//!
//! Architecture (TIM-191):
//! - Each backup destination has its own index at `<dest>/.amber-meta/index.db`
//! - The app reads snapshots from these per-destination indexes
//! - jobs.json defines which destinations to look at
//!
//! IMPORTANT: This is DEV-ONLY and should never be used in production.

use crate::error::{AmberError, Result};
use crate::services::index_service::IndexService;
use crate::services::store::Store;
use std::fs;
use std::path::PathBuf;
use std::sync::Arc;
use std::time::Instant;

/// Seeding result with stats
#[derive(Debug, Clone, serde::Serialize)]
pub struct SeedResult {
    pub jobs_created: usize,
    pub snapshots_created: usize,
    pub files_created: usize,
    pub total_size_bytes: u64,
    pub duration_ms: u64,
}

/// Benchmark result
#[derive(Debug, Clone, serde::Serialize)]
pub struct BenchmarkResult {
    pub operation: String,
    pub iterations: usize,
    pub avg_ms: f64,
    pub min_ms: f64,
    pub max_ms: f64,
    pub total_ms: f64,
}

pub struct DevSeeder {
    store: Arc<Store>,
    mock_data_path: Option<PathBuf>,
    app_data_path: PathBuf,
}

impl DevSeeder {
    pub fn new(
        _index_service: &Arc<IndexService>,
        store: &Arc<Store>,
        app_data_path: PathBuf,
    ) -> Self {
        Self {
            store: Arc::clone(store),
            mock_data_path: None,
            app_data_path,
        }
    }

    /// Set the path to the mock-data folder
    pub fn with_mock_data_path(mut self, path: PathBuf) -> Self {
        self.mock_data_path = Some(path);
        self
    }

    /// Get the path to the pre-generated jobs.json
    fn source_jobs_path(&self) -> Option<PathBuf> {
        self.mock_data_path.as_ref().map(|p| p.join("jobs.json"))
    }

    /// Get paths to dev backup destinations
    fn get_dev_dest_paths(&self) -> Vec<PathBuf> {
        let mut paths = Vec::new();
        if let Some(mock_path) = &self.mock_data_path {
            // Check for dev- prefixed backup folders
            for name in &[
                "dev-documents-backup",
                "dev-media-archive",
                "stress-test-backup",
            ] {
                let path = mock_path.join(name);
                if path.exists() && path.join(".amber-meta").exists() {
                    paths.push(path);
                }
            }
        }
        paths
    }

    /// Check if pre-generated mock data exists
    /// Now checks for jobs.json and at least one backup destination with .amber-meta
    fn has_source_data(&self) -> bool {
        let has_jobs = self.source_jobs_path().map(|p| p.exists()).unwrap_or(false);

        let has_destinations = !self.get_dev_dest_paths().is_empty();

        has_jobs && has_destinations
    }

    /// Check if dev data already exists in the app
    pub fn is_seeded(&self) -> Result<bool> {
        let jobs = self.store.load_jobs()?;
        let dev_jobs: Vec<_> = jobs
            .iter()
            .filter(|j| j.id.starts_with("dev-") || j.id == "stress-test-backup")
            .collect();

        if dev_jobs.is_empty() {
            return Ok(false);
        }

        // Check if at least one dev job has snapshots via manifest
        for job in dev_jobs {
            let manifest_path = PathBuf::from(&job.dest_path)
                .join(".amber-meta")
                .join("manifest.json");
            if manifest_path.exists() {
                return Ok(true);
            }
        }

        Ok(false)
    }

    /// Seed development data by copying jobs.json
    /// The per-destination indexes already exist in the mock-data folders
    pub fn seed(&mut self) -> Result<SeedResult> {
        // Check if already seeded
        if self.is_seeded()? {
            log::info!("Dev data already exists. Use 'Clear' first to re-seed.");
            return self.get_existing_stats();
        }

        let start = Instant::now();

        // Check if we have pre-generated data
        if !self.has_source_data() {
            return Err(AmberError::Index(
                "No pre-generated mock data found. Run: python3 scripts/dev/generate-mock-data.py"
                    .to_string(),
            ));
        }

        log::info!("Importing pre-generated mock data...");

        // Copy jobs.json - this is all we need to do!
        // The per-destination indexes are already at mock-data/<job-id>/.amber-meta/index.db
        if let Some(source_jobs) = self.source_jobs_path() {
            if source_jobs.exists() {
                let dest_jobs = self.app_data_path.join("jobs.json");
                fs::copy(&source_jobs, &dest_jobs)
                    .map_err(|e| AmberError::Index(format!("Failed to copy jobs.json: {}", e)))?;
                log::info!("Copied jobs.json to {:?}", dest_jobs);
            }
        }

        let duration = start.elapsed();

        // Get stats from the per-destination indexes
        self.get_existing_stats().map(|mut result| {
            result.duration_ms = duration.as_millis() as u64;
            result.jobs_created = self.get_dev_dest_paths().len();
            result
        })
    }

    /// Get stats from existing dev data by querying per-destination indexes
    fn get_existing_stats(&self) -> Result<SeedResult> {
        let mut total_snapshots = 0i64;
        let mut total_files = 0i64;
        let mut total_size = 0i64;

        for dest_path in self.get_dev_dest_paths() {
            let index_path = dest_path.join(".amber-meta").join("index.db");
            if !index_path.exists() {
                continue;
            }

            // Open the per-destination index
            if let Ok(conn) = rusqlite::Connection::open(&index_path) {
                let snapshot_count: i64 = conn
                    .query_row("SELECT COUNT(*) FROM snapshots", [], |row| row.get(0))
                    .unwrap_or(0);

                let file_count: i64 = conn
                    .query_row("SELECT COUNT(*) FROM files", [], |row| row.get(0))
                    .unwrap_or(0);

                let size: i64 = conn
                    .query_row(
                        "SELECT COALESCE(SUM(total_size), 0) FROM snapshots",
                        [],
                        |row| row.get(0),
                    )
                    .unwrap_or(0);

                total_snapshots += snapshot_count;
                total_files += file_count;
                total_size += size;

                log::debug!(
                    "Stats from {:?}: {} snapshots, {} files, {} bytes",
                    dest_path.file_name(),
                    snapshot_count,
                    file_count,
                    size
                );
            }
        }

        Ok(SeedResult {
            jobs_created: 0,
            snapshots_created: total_snapshots as usize,
            files_created: total_files as usize,
            total_size_bytes: total_size as u64,
            duration_ms: 0,
        })
    }

    /// Run benchmarks on the seeded data using per-destination indexes
    pub fn run_benchmarks(&self) -> Result<Vec<BenchmarkResult>> {
        // Find a dev destination with data
        let dest_paths = self.get_dev_dest_paths();
        let dev_dest = dest_paths
            .iter()
            .find(|p| p.file_name().map(|n| n.to_str()) == Some(Some("dev-documents-backup")))
            .or_else(|| dest_paths.first());

        let Some(dest_path) = dev_dest else {
            return Err(AmberError::Index("No dev destinations found".to_string()));
        };

        let dest_str = dest_path.to_string_lossy().to_string();

        // Create an index service for this destination
        let dest_index = IndexService::for_destination(&dest_str)?;

        Ok(vec![
            self.benchmark_list_snapshots_dest(&dest_index, "dev-documents-backup")?,
            self.benchmark_directory_contents_dest(&dest_index, "dev-documents-backup")?,
            self.benchmark_fts_search_common_dest(&dest_index)?,
            self.benchmark_fts_search_rare_dest(&dest_index)?,
            self.benchmark_snapshot_stats_dest(&dest_index, "dev-documents-backup")?,
        ])
    }

    fn benchmark_list_snapshots_dest(
        &self,
        index: &IndexService,
        job_id: &str,
    ) -> Result<BenchmarkResult> {
        let iterations = 100;
        let mut times = Vec::with_capacity(iterations);

        for _ in 0..iterations {
            let start = Instant::now();
            let _ = index.list_snapshots(job_id)?;
            times.push(start.elapsed().as_secs_f64() * 1000.0);
        }

        Ok(calculate_stats("list_snapshots", &times))
    }

    fn benchmark_directory_contents_dest(
        &self,
        index: &IndexService,
        job_id: &str,
    ) -> Result<BenchmarkResult> {
        let snapshots = index.list_snapshots(job_id)?;
        if snapshots.is_empty() {
            return Ok(BenchmarkResult {
                operation: "get_directory_contents".to_string(),
                iterations: 0,
                avg_ms: 0.0,
                min_ms: 0.0,
                max_ms: 0.0,
                total_ms: 0.0,
            });
        }

        let timestamp = snapshots[0].timestamp;
        let iterations = 100;
        let mut times = Vec::with_capacity(iterations);

        // Try common directory names
        let test_dirs = ["Projects", "Documents", "Notes", ""];
        let test_dir = test_dirs
            .iter()
            .find(|d| index.get_directory_contents(job_id, timestamp, d).is_ok())
            .unwrap_or(&"");

        for _ in 0..iterations {
            let start = Instant::now();
            let _ = index.get_directory_contents(job_id, timestamp, test_dir)?;
            times.push(start.elapsed().as_secs_f64() * 1000.0);
        }

        Ok(calculate_stats("get_directory_contents", &times))
    }

    fn benchmark_fts_search_common_dest(&self, index: &IndexService) -> Result<BenchmarkResult> {
        let iterations = 100;
        let mut times = Vec::with_capacity(iterations);
        let search_terms = ["document", "photo", "report", "video", "config"];

        for i in 0..iterations {
            let term = search_terms[i % search_terms.len()];
            let start = Instant::now();
            let _ = index.search_files_global(term, None, 50)?;
            times.push(start.elapsed().as_secs_f64() * 1000.0);
        }

        Ok(calculate_stats("fts5_search_common", &times))
    }

    fn benchmark_fts_search_rare_dest(&self, index: &IndexService) -> Result<BenchmarkResult> {
        let iterations = 100;
        let mut times = Vec::with_capacity(iterations);
        let search_terms = [
            "kubernetes",
            "terraform",
            "whitepaper",
            "composition",
            "prototype",
        ];

        for i in 0..iterations {
            let term = search_terms[i % search_terms.len()];
            let start = Instant::now();
            let _ = index.search_files_global(term, None, 50)?;
            times.push(start.elapsed().as_secs_f64() * 1000.0);
        }

        Ok(calculate_stats("fts5_search_rare", &times))
    }

    fn benchmark_snapshot_stats_dest(
        &self,
        index: &IndexService,
        job_id: &str,
    ) -> Result<BenchmarkResult> {
        let snapshots = index.list_snapshots(job_id)?;
        if snapshots.is_empty() {
            return Ok(BenchmarkResult {
                operation: "get_snapshot_stats".to_string(),
                iterations: 0,
                avg_ms: 0.0,
                min_ms: 0.0,
                max_ms: 0.0,
                total_ms: 0.0,
            });
        }

        let iterations = 100;
        let mut times = Vec::with_capacity(iterations);

        for i in 0..iterations {
            let snapshot = &snapshots[i % snapshots.len()];
            let start = Instant::now();
            let _ = index.get_snapshot_stats(job_id, snapshot.timestamp)?;
            times.push(start.elapsed().as_secs_f64() * 1000.0);
        }

        Ok(calculate_stats("get_snapshot_stats", &times))
    }
}

fn calculate_stats(operation: &str, times: &[f64]) -> BenchmarkResult {
    if times.is_empty() {
        return BenchmarkResult {
            operation: operation.to_string(),
            iterations: 0,
            avg_ms: 0.0,
            min_ms: 0.0,
            max_ms: 0.0,
            total_ms: 0.0,
        };
    }

    let total: f64 = times.iter().sum();
    let avg = total / times.len() as f64;
    let min = times.iter().cloned().fold(f64::INFINITY, f64::min);
    let max = times.iter().cloned().fold(f64::NEG_INFINITY, f64::max);

    BenchmarkResult {
        operation: operation.to_string(),
        iterations: times.len(),
        avg_ms: avg,
        min_ms: min,
        max_ms: max,
        total_ms: total,
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_calculate_stats() {
        let times = vec![1.0, 2.0, 3.0, 4.0, 5.0];
        let result = calculate_stats("test", &times);

        assert_eq!(result.operation, "test");
        assert_eq!(result.iterations, 5);
        assert!((result.avg_ms - 3.0).abs() < 0.001);
        assert!((result.min_ms - 1.0).abs() < 0.001);
        assert!((result.max_ms - 5.0).abs() < 0.001);
        assert!((result.total_ms - 15.0).abs() < 0.001);
    }

    #[test]
    fn test_calculate_stats_empty() {
        let times: Vec<f64> = vec![];
        let result = calculate_stats("empty", &times);

        assert_eq!(result.iterations, 0);
        assert_eq!(result.avg_ms, 0.0);
    }
}
