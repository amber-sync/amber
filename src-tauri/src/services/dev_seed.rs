//! Development data seeding for testing Timeline and FTS5 performance
//!
//! This module imports pre-generated mock data from the `mock-data/` folder.
//! The data is generated by `scripts/generate-mock-data.py` which creates:
//! - Two jobs: "Documents Backup" and "Media Archive"
//! - 85 snapshots spanning 2 years
//! - ~4.7 million files with realistic directory structures
//! - ~1.5 GB SQLite database with FTS5 index
//!
//! IMPORTANT: This is DEV-ONLY and should never be used in production.

use crate::error::{AmberError, Result};
use crate::services::store::Store;
use std::fs;
use std::path::PathBuf;
use std::sync::Arc;
use std::time::Instant;

/// Seeding result with stats
#[derive(Debug, Clone, serde::Serialize)]
pub struct SeedResult {
    pub jobs_created: usize,
    pub snapshots_created: usize,
    pub files_created: usize,
    pub total_size_bytes: u64,
    pub duration_ms: u64,
}

/// Benchmark result
#[derive(Debug, Clone, serde::Serialize)]
pub struct BenchmarkResult {
    pub operation: String,
    pub iterations: usize,
    pub avg_ms: f64,
    pub min_ms: f64,
    pub max_ms: f64,
    pub total_ms: f64,
}

pub struct DevSeeder {
    index_service: Arc<crate::services::index_service::IndexService>,
    store: Arc<Store>,
    mock_data_path: Option<PathBuf>,
    app_data_path: PathBuf,
}

impl DevSeeder {
    pub fn new(
        index_service: &Arc<crate::services::index_service::IndexService>,
        store: &Arc<Store>,
        app_data_path: PathBuf,
    ) -> Self {
        Self {
            index_service: Arc::clone(index_service),
            store: Arc::clone(store),
            mock_data_path: None,
            app_data_path,
        }
    }

    /// Set the path to the mock-data folder
    pub fn with_mock_data_path(mut self, path: PathBuf) -> Self {
        self.mock_data_path = Some(path);
        self
    }

    /// Get the path to the pre-generated dev database
    fn source_db_path(&self) -> Option<PathBuf> {
        self.mock_data_path.as_ref().map(|p| p.join("dev-index.db"))
    }

    /// Get the path to the pre-generated jobs.json
    fn source_jobs_path(&self) -> Option<PathBuf> {
        self.mock_data_path.as_ref().map(|p| p.join("jobs.json"))
    }

    /// Check if pre-generated mock data exists
    fn has_source_data(&self) -> bool {
        self.source_db_path()
            .map(|p| p.exists())
            .unwrap_or(false)
    }

    /// Check if dev data already exists in the app
    pub fn is_seeded(&self) -> Result<bool> {
        let jobs = self.store.load_jobs()?;
        let has_dev_jobs = jobs.iter().any(|j| j.id.starts_with("dev-"));

        if has_dev_jobs {
            let snapshots = self.index_service.list_snapshots("dev-documents-backup")?;
            return Ok(!snapshots.is_empty());
        }

        Ok(false)
    }

    /// Seed development data by copying pre-generated files
    pub fn seed(&mut self) -> Result<SeedResult> {
        // Check if already seeded
        if self.is_seeded()? {
            log::info!("Dev data already exists. Use 'Clear' first to re-seed.");
            return self.get_existing_stats();
        }

        let start = Instant::now();

        // Check if we have pre-generated data
        if !self.has_source_data() {
            return Err(AmberError::Index(
                "No pre-generated mock data found. Run: python3 scripts/generate-mock-data.py".to_string()
            ));
        }

        log::info!("Importing pre-generated mock data...");

        // Copy jobs.json
        if let Some(source_jobs) = self.source_jobs_path() {
            if source_jobs.exists() {
                let dest_jobs = self.app_data_path.join("jobs.json");
                fs::copy(&source_jobs, &dest_jobs)
                    .map_err(|e| AmberError::Index(format!("Failed to copy jobs.json: {}", e)))?;
                log::info!("Copied jobs.json to {:?}", dest_jobs);
            }
        }

        // Copy index.db (this is the big one)
        if let Some(source_db) = self.source_db_path() {
            let dest_db = self.app_data_path.join("index.db");

            // Remove existing db first
            if dest_db.exists() {
                fs::remove_file(&dest_db).ok();
            }
            // Also remove WAL files
            let wal_path = self.app_data_path.join("index.db-wal");
            let shm_path = self.app_data_path.join("index.db-shm");
            fs::remove_file(&wal_path).ok();
            fs::remove_file(&shm_path).ok();

            log::info!("Copying database (~1.5 GB)...");
            fs::copy(&source_db, &dest_db)
                .map_err(|e| AmberError::Index(format!("Failed to copy index.db: {}", e)))?;
            log::info!("Copied index.db to {:?}", dest_db);
        }

        let duration = start.elapsed();

        // Get stats from the newly copied database
        // Need to reconnect to the new database
        self.get_existing_stats().map(|mut result| {
            result.duration_ms = duration.as_millis() as u64;
            result.jobs_created = 2;
            result
        })
    }

    /// Get stats from existing dev data
    fn get_existing_stats(&self) -> Result<SeedResult> {
        let conn = self.index_service.get_connection_for_stats()?;

        let snapshot_count: i64 = conn
            .query_row(
                "SELECT COUNT(*) FROM snapshots WHERE job_id LIKE 'dev-%'",
                [],
                |row| row.get(0),
            )
            .unwrap_or(0);

        let file_count: i64 = conn
            .query_row(
                "SELECT COUNT(*) FROM files f JOIN snapshots s ON f.snapshot_id = s.id WHERE s.job_id LIKE 'dev-%'",
                [],
                |row| row.get(0),
            )
            .unwrap_or(0);

        let total_size: i64 = conn
            .query_row(
                "SELECT COALESCE(SUM(total_size), 0) FROM snapshots WHERE job_id LIKE 'dev-%'",
                [],
                |row| row.get(0),
            )
            .unwrap_or(0);

        Ok(SeedResult {
            jobs_created: 0,
            snapshots_created: snapshot_count as usize,
            files_created: file_count as usize,
            total_size_bytes: total_size as u64,
            duration_ms: 0,
        })
    }

    /// Run benchmarks on the seeded data
    pub fn run_benchmarks(&self) -> Result<Vec<BenchmarkResult>> {
        let mut results = Vec::new();

        results.push(self.benchmark_list_snapshots()?);
        results.push(self.benchmark_directory_contents()?);
        results.push(self.benchmark_fts_search_common()?);
        results.push(self.benchmark_fts_search_rare()?);
        results.push(self.benchmark_snapshot_stats()?);

        Ok(results)
    }

    fn benchmark_list_snapshots(&self) -> Result<BenchmarkResult> {
        let iterations = 100;
        let mut times = Vec::with_capacity(iterations);

        for _ in 0..iterations {
            let start = Instant::now();
            let _ = self.index_service.list_snapshots("dev-documents-backup")?;
            times.push(start.elapsed().as_secs_f64() * 1000.0);
        }

        Ok(calculate_stats("list_snapshots", &times))
    }

    fn benchmark_directory_contents(&self) -> Result<BenchmarkResult> {
        let snapshots = self.index_service.list_snapshots("dev-documents-backup")?;
        if snapshots.is_empty() {
            return Ok(BenchmarkResult {
                operation: "get_directory_contents".to_string(),
                iterations: 0,
                avg_ms: 0.0,
                min_ms: 0.0,
                max_ms: 0.0,
                total_ms: 0.0,
            });
        }

        let timestamp = snapshots[0].timestamp;
        let iterations = 100;
        let mut times = Vec::with_capacity(iterations);

        for _ in 0..iterations {
            let start = Instant::now();
            let _ = self.index_service.get_directory_contents(
                "dev-documents-backup",
                timestamp,
                "Documents",
            )?;
            times.push(start.elapsed().as_secs_f64() * 1000.0);
        }

        Ok(calculate_stats("get_directory_contents", &times))
    }

    fn benchmark_fts_search_common(&self) -> Result<BenchmarkResult> {
        let iterations = 100;
        let mut times = Vec::with_capacity(iterations);
        let search_terms = ["document", "photo", "report", "video", "config"];

        for i in 0..iterations {
            let term = search_terms[i % search_terms.len()];
            let start = Instant::now();
            let _ = self.index_service.search_files_global(term, None, 50)?;
            times.push(start.elapsed().as_secs_f64() * 1000.0);
        }

        Ok(calculate_stats("fts5_search_common", &times))
    }

    fn benchmark_fts_search_rare(&self) -> Result<BenchmarkResult> {
        let iterations = 100;
        let mut times = Vec::with_capacity(iterations);
        let search_terms = ["kubernetes", "terraform", "whitepaper", "composition", "prototype"];

        for i in 0..iterations {
            let term = search_terms[i % search_terms.len()];
            let start = Instant::now();
            let _ = self.index_service.search_files_global(term, None, 50)?;
            times.push(start.elapsed().as_secs_f64() * 1000.0);
        }

        Ok(calculate_stats("fts5_search_rare", &times))
    }

    fn benchmark_snapshot_stats(&self) -> Result<BenchmarkResult> {
        let snapshots = self.index_service.list_snapshots("dev-documents-backup")?;
        if snapshots.is_empty() {
            return Ok(BenchmarkResult {
                operation: "get_snapshot_stats".to_string(),
                iterations: 0,
                avg_ms: 0.0,
                min_ms: 0.0,
                max_ms: 0.0,
                total_ms: 0.0,
            });
        }

        let iterations = 100;
        let mut times = Vec::with_capacity(iterations);

        for i in 0..iterations {
            let snapshot = &snapshots[i % snapshots.len()];
            let start = Instant::now();
            let _ = self
                .index_service
                .get_snapshot_stats("dev-documents-backup", snapshot.timestamp)?;
            times.push(start.elapsed().as_secs_f64() * 1000.0);
        }

        Ok(calculate_stats("get_snapshot_stats", &times))
    }
}

fn calculate_stats(operation: &str, times: &[f64]) -> BenchmarkResult {
    if times.is_empty() {
        return BenchmarkResult {
            operation: operation.to_string(),
            iterations: 0,
            avg_ms: 0.0,
            min_ms: 0.0,
            max_ms: 0.0,
            total_ms: 0.0,
        };
    }

    let total: f64 = times.iter().sum();
    let avg = total / times.len() as f64;
    let min = times.iter().cloned().fold(f64::INFINITY, f64::min);
    let max = times.iter().cloned().fold(f64::NEG_INFINITY, f64::max);

    BenchmarkResult {
        operation: operation.to_string(),
        iterations: times.len(),
        avg_ms: avg,
        min_ms: min,
        max_ms: max,
        total_ms: total,
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_calculate_stats() {
        let times = vec![1.0, 2.0, 3.0, 4.0, 5.0];
        let result = calculate_stats("test", &times);

        assert_eq!(result.operation, "test");
        assert_eq!(result.iterations, 5);
        assert!((result.avg_ms - 3.0).abs() < 0.001);
        assert!((result.min_ms - 1.0).abs() < 0.001);
        assert!((result.max_ms - 5.0).abs() < 0.001);
        assert!((result.total_ms - 15.0).abs() < 0.001);
    }

    #[test]
    fn test_calculate_stats_empty() {
        let times: Vec<f64> = vec![];
        let result = calculate_stats("empty", &times);

        assert_eq!(result.iterations, 0);
        assert_eq!(result.avg_ms, 0.0);
    }
}
